{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Getting Started with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import difflib\n",
    "import datetime\n",
    "\n",
    "#sc is the sparkContext that gets created whe pyspark is started\n",
    "hc = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If SparkContext doesnot get Intialized by itself, following set of commands may be used:\n",
    "\n",
    "import findspark <br>\n",
    "findspark.init() <br>\n",
    "import pyspark # only run after findspark.init() <br>\n",
    "from pyspark.sql import SparkSession <br>\n",
    "spark = SparkSession.builder.getOrCreate() <br>\n",
    "import pandas as pd <br>\n",
    "sc = spark.sparkContext <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Make a sample dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using pandas Dataframe:\n",
    "\n",
    "Read Data into Pandas from csv, txt, excel files, etc. <br> \n",
    "Define a Schema: columns and their data types <br>\n",
    "Use CreateDataFrame() to convert to spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = {'PassengerId': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
    "         'Name': {0: 'Owen', 1: 'Florence', 2: 'Laina', 3: 'Lily', 4: 'William'},\n",
    "         'Gender': {0:'M', 1: 'F', 2: 'F', 3: 'F', 4: 'M'},\n",
    "         'Survived': {0: 0, 1: 1, 2: 1, 3: 1, 4: 0}}\n",
    "\n",
    "data2 = {'PassengerId': {0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
    "         'Age': {0: 22, 1: 38, 2: 26, 3: 35, 4: 35},\n",
    "         'Fare': {0: 7.3, 1: 71.3, 2: 7.9, 3: 53.1, 4: 8.0},\n",
    "         'Pclass': {0: 3, 1: 1, 2: 3, 3: 1, 4: 3}}\n",
    "\n",
    "df1_pd = pd.DataFrame(data1, columns=data1.keys())\n",
    "df2_pd = pd.DataFrame(data2, columns=data2.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without defining Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = hc.createDataFrame(df1_pd)\n",
    "df2 = hc.createDataFrame(df2_pd)\n",
    "#df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- PassengerId: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Survived: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Defined Data Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_schema_1 = StructType([StructField('Gender',StringType(),True),\n",
    "                          StructField('PassengerId',IntegerType(),True),\n",
    "                          StructField('Name',StringType(),True),\n",
    "                          StructField('Survived',IntegerType(),True) ])\n",
    "# for date type: StructField('MeetingDate',DateType(),True) ])\n",
    "#True denotes that data field is nullable\n",
    "df_spark_1 = hc.createDataFrame(df1_pd,df_schema_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the same for df2_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Using Hadoop Tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By importing the whole table: hc.table('table name')\n",
    "#cust_1: database name in hadoop; #abc_xxx : table name\n",
    "data = hc.table('cust_1.abc_xxx') \n",
    "# data is now a pyspark dataframe\n",
    "\n",
    "# By running a sql query:\n",
    "\n",
    "data = hc.sql(''' select name, r_no, age from cust_1.abc_xxx where trim(age) = '30' ''')\n",
    "\n",
    "#data is now a pyspark dataframe\n",
    "\n",
    "# To Note: trim is used in string types to ensure removal of white spaces, since data in hive can be unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Change DataFrames Properties\n",
    "#### 2.1 Change Column Type\n",
    " Available types include <br>\n",
    "\n",
    "BinaryType <br>\n",
    "BooleanType <br>\n",
    "ByteType <br>\n",
    "DoubleType <br>\n",
    "DateType <br>\n",
    "FloatType <br>\n",
    "IntegerType <br>\n",
    "etc.\n",
    "\n",
    "#### Q. Change data type of PassengerID to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# .withColumn return a DataFrame by adding a column or replacing the existing column that has the same name.\n",
    "df_spark_2 = df_spark_1.withColumn(\"PassengerId\", df_spark_1[\"PassengerId\"].cast(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gender', 'string'),\n",
       " ('PassengerId', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Survived', 'int')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Change Column Name\n",
    "\n",
    "#### Q. Rename Gender Column to Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_spark_3 = df_spark_2.withColumnRenamed(\"Gender\", \"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- PassengerId: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Modify Column Values and create new columns\n",
    "\n",
    "#### Q1. Modify values in Sex Column: M to Male and F to female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_spark_4 = df_spark_3.withColumn(\"Sex\", F.when(trim(df_spark_3['Sex']) == 'M', 'Male').\\\n",
    "                                   otherwise(F.when(trim(df_spark_3['Sex']) == 'F', 'Female').otherwise('NA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Sex: string, PassengerId: string, Name: string, Survived: int]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Q2. Create New column 'type_of_data' with constant value: 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_spark_5 = df_spark_4.withColumn('type_of_data', lit('train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Order DataFrame by Specified Column(s)\n",
    "\n",
    "#### Q. Order by  descending order: PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+--------+\n",
      "|   Sex|PassengerId|    Name|Survived|\n",
      "+------+-----------+--------+--------+\n",
      "|  Male|          5| William|       0|\n",
      "|Female|          4|    Lily|       1|\n",
      "|Female|          3|   Laina|       1|\n",
      "|Female|          2|Florence|       1|\n",
      "|  Male|          1|    Owen|       0|\n",
      "+------+-----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_4.sort(df_spark_4.PassengerId.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+--------+\n",
      "|   Sex|PassengerId|    Name|Survived|\n",
      "+------+-----------+--------+--------+\n",
      "|  Male|          5| William|       0|\n",
      "|Female|          4|    Lily|       1|\n",
      "|Female|          3|   Laina|       1|\n",
      "|Female|          2|Florence|       1|\n",
      "|  Male|          1|    Owen|       0|\n",
      "+------+-----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_4.sort('PassengerId', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Filter by Specified Column(s)\n",
    "\n",
    "#### Q. Filter out the female population from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter takes column expression or SQL expression ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Using Column expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_data = df_spark_4.filter(trim(col('Sex')) == 'Female')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  col('columnname') is eqivalent to dataframe['columnname'] equivalent to dataframe.columnname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Using SQL expression.Note the double and single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_data_2 = df_spark_4.filter(\"Sex='Female'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Summarize/Aggregate and group by\n",
    "\n",
    "#### Q. Group By Passenger Class and find avergae Fare and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------+\n",
      "|Pclass|          avg(Age)|        avg(Fare)|\n",
      "+------+------------------+-----------------+\n",
      "|     1|              36.5|             62.2|\n",
      "|     3|27.666666666666668|7.733333333333333|\n",
      "+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf2 = df2.groupby('Pclass')\n",
    "\n",
    "avg_cols = ['Age', 'Fare']\n",
    "gdf2.avg(*avg_cols).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Group By Passenger Class and find Total Fare and Average Age and count of passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+---------+\n",
      "|Pclass|count(1)|          avg(Age)|sum(Fare)|\n",
      "+------+--------+------------------+---------+\n",
      "|     1|       2|              36.5|    124.4|\n",
      "|     3|       3|27.666666666666668|     23.2|\n",
      "+------+--------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf2.agg({'*': 'count', 'Age': 'avg', 'Fare':'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. rename the columns count(1), avg(Age) etc, \n",
    "using toDF()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+----------+\n",
      "|Pclass|counts|       average_age|total_fare|\n",
      "+------+------+------------------+----------+\n",
      "|     1|     2|              36.5|     124.4|\n",
      "|     3|     3|27.666666666666668|      23.2|\n",
      "+------+------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gdf2.agg({'*': 'count', 'Age': 'avg', 'Fare':'sum'})\\\n",
    "    .toDF('Pclass', 'counts', 'average_age', 'total_fare')\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Arrange passenger class by total fare in ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|Pclass|sum(Fare)|\n",
      "+------+---------+\n",
      "|     3|     23.2|\n",
      "|     1|    124.4|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('Pclass').agg({'Fare':'sum'}).sort('sum(Fare)', ascending = True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Get Count of distinct Passenger classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select('Pclass').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Pclass|\n",
      "+------+\n",
      "|     1|\n",
      "|     3|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('Pclass').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. Get Count of 'Distinct' Passenger Ids by Sex\n",
    "\n",
    "#####Note 1: countDistinct here is a SQL Function hence 'F.countDistinct'; <br>\n",
    "#####Note 2: Like F.countDistinct, F.sum, F.avg, F.max, etc sql functions can be used. <br>\n",
    "#####Note 3: here there is no repitition of passenger ids hence count gives same result as count distinct function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|count(PassengerId)|\n",
      "+------+------------------+\n",
      "|Female|                 3|\n",
      "|  Male|                 2|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_4.groupby('Sex').agg(F.countDistinct('PassengerId')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|Pclass|sum(Fare)|\n",
      "+------+---------+\n",
      "|     1|    124.4|\n",
      "|     3|     23.2|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('Pclass').agg(F.sum('Fare')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Joins and unions¶\n",
    "####There are two ways to combine dataframes --- joins and unions. The idea here is the same as joining and unioning tables in SQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Joins¶ Q.Join the two titanic dataframes by the column PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+--------+--------+----+---+------+\n",
      "|PassengerId|Gender|    Name|Survived|Fare|Age|Pclass|\n",
      "+-----------+------+--------+--------+----+---+------+\n",
      "|          1|     M|    Owen|       0| 7.3| 22|     3|\n",
      "|          2|     F|Florence|       1|71.3| 38|     1|\n",
      "|          3|     F|   Laina|       1| 7.9| 26|     3|\n",
      "|          4|     F|    Lily|       1|53.1| 35|     1|\n",
      "|          5|     M| William|       0| 8.0| 35|     3|\n",
      "+-----------+------+--------+--------+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2, ['PassengerId']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
